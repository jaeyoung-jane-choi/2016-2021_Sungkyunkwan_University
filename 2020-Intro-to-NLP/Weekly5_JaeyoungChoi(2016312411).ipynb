{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Weekly5-JaeyoungChoi(2016312411).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VaZ-d6ARx4k",
        "colab_type": "text"
      },
      "source": [
        "**(1) Original Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNSVAsYgIQQV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "8cee3a7a-ee42-41f8-b254-fc25c2e7d7ef"
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np\n",
        "import nltk\n",
        "import re\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords "
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rlFf48FJxFx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get the train data with following categories \n",
        "#remove the metadata information \n",
        "category = ['alt.atheism','talk.religion.misc','comp.graphics','sci.space']\n",
        "newsgroups_train = fetch_20newsgroups(subset='train',categories = category, remove= ('headers','footers', 'quotes'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lh0bZVuoLoFf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#vectorize by TfidfVectorizer with the vocabulary in the train data \n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectors = vectorizer.fit_transform(newsgroups_train.data) #fit.transform vectorizes vocab with the train data \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVJNJYbUMDEV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB #since there are several categories \n",
        "from sklearn import metrics "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RI4Bp-GQMKgW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "newsgroups_test = fetch_20newsgroups(subset='test', categories=category, remove= ('headers','footers', 'quotes'))\n",
        "vector_test = vectorizer.transform(newsgroups_test.data) #use transform not fit_transform to generate vectors related to train data vectors "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mB1abdarMmc9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "45b69604-9b31-4bde-f031-233e3ebec2d3"
      },
      "source": [
        "clf = MultinomialNB(alpha =0.1)\n",
        "clf.fit(vectors, newsgroups_train.target) #fit the model with the train data \n",
        "pred = clf.predict(vector_test)\n",
        "metrics.f1_score(newsgroups_test.target, pred, average= 'macro') "
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7564535630493667"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xrm7GtQSFHN",
        "colab_type": "text"
      },
      "source": [
        "**(2) Additional pre-processing:deleting stop words**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cg7k7EexRwNA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b2d4d388-e3c8-4e64-b15b-52922fae7087"
      },
      "source": [
        "#look at the vocaulary dictionary that has been processed \n",
        "#vectorizer.vocabulary_ #dictionary which shows all the words with index as the item (key: word, item: index of word )\n",
        "#look at the feature names of vocab vectors\n",
        "vectorizer.get_feature_names() #feature names of dic(=key)\n",
        "len(vectorizer.get_feature_names()) #26879 words inside the vocab vector"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26879"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhadvJncb3oT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "e4ca9b3d-f7bb-439c-a6e6-2d5f78d721dc"
      },
      "source": [
        "newsgroups_train['data'][0] #the data is inside the dictionary['data] with sentences to lists "
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Hi,\\n\\nI've noticed that if you only save a model (with all your mapping planes\\npositioned carefully) to a .3DS file that when you reload it after restarting\\n3DS, they are given a default position and orientation.  But if you save\\nto a .PRJ file their positions/orientation are preserved.  Does anyone\\nknow why this information is not stored in the .3DS file?  Nothing is\\nexplicitly said in the manual about saving texture rules in the .PRJ file. \\nI'd like to be able to read the texture rule information, does anyone have \\nthe format for the .PRJ file?\\n\\nIs the .CEL file format available from somewhere?\\n\\nRych\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfvV7HOzeTp8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#preperation for removing stop words : \n",
        "newsgroups_train['filenames'] #an array of the data -not needed  \n",
        "newsgroups_train['target_names']\n",
        "newsgroups_train['target']\n",
        "newsgroups_train['DESCR'] #not needed \n",
        "\n",
        "data = newsgroups_train['data']  #includes the news data \n",
        "target_name =newsgroups_train['target_names']  #includes the news data target_names\n",
        "target = newsgroups_train['target'] #includes each data's target \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiNFX2klRaaI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "106ed3f2-46f0-4035-f0cb-c170457e4422"
      },
      "source": [
        "#delete stop words in the trainset :takes long time since goes through every sentence, token \n",
        "\n",
        "clean = []\n",
        "for sentence in data:\n",
        "  #print(sentence)\n",
        "  cleanwords = []\n",
        "  words = nltk.word_tokenize(sentence)\n",
        "  for w in words:\n",
        "    w = w.lower()\n",
        "    if w not in stopwords.words('english'):\n",
        "      cleanwords.append(w)\n",
        "  clean.append(cleanwords)\n",
        "\n",
        "len(clean)"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2034"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkZ5apClkqSl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#made useful dataset only for inlcuding needed data \n",
        "\n",
        "train_data = {'data': clean, 'target_name': target_name, 'target': target} \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLho-eNrimJg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "78a012f4-44da-4cf5-9bb9-e7194a9e2215"
      },
      "source": [
        "type(newsgroups_train['data']) # type is a list of each news words \n",
        "train_data['data'] #list\n",
        "train_data['target'] #array"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 3, 2, ..., 1, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOi66XlRrVHV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#The words need to be not in a list, but in strings (should be list of words, not list of lists )\n",
        "data=[]\n",
        "element = ''\n",
        "for lists in train_data['data']:\n",
        "  for words in lists:\n",
        "    element=' '.join(lists)\n",
        "  data.append(element)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xh-n42OksGWL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "c2873c22-4d96-4d15-cb60-801522e7a62f"
      },
      "source": [
        "data[0]"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"hi , 've noticed save model ( mapping planes positioned carefully ) .3ds file reload restarting 3ds , given default position orientation . save .prj file positions/orientation preserved . anyone know information stored .3ds file ? nothing explicitly said manual saving texture rules .prj file . 'd like able read texture rule information , anyone format .prj file ? .cel file format available somewhere ? rych\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4DRABNmirs4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "35efd871-004d-4b38-b2f2-1076d25f8a7a"
      },
      "source": [
        "data_array = np.array(data)\n",
        "#train = np.concatenate((data_array, train_data['target']), axis = 1)\n",
        "np_data =np.column_stack((data_array,train_data['target']))\n",
        "np_data.shape #2034 list of words with  2 columns "
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2034, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xY_qbB2Igy_t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clean_vector = vectorizer.fit_transform(np_data[:,0]) #fit.transform vectorizes vocab with the train data with stop words deleted "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iOF-JI8tJpW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fae3cc86-1910-48fb-c837-cc4ced2a1a96"
      },
      "source": [
        "#do not need to do the same thing for the text data : since vectorize according to the train data \n",
        "clean_vector_test = vectorizer.transform(newsgroups_test.data)\n",
        "clf2 = MultinomialNB(alpha =0.1)\n",
        "clf2.fit(clean_vector, train_data['target']) #fit the model with the train data\n",
        "pred2 = clf2.predict(clean_vector_test)\n",
        "metrics.f1_score(newsgroups_test.target, pred2, average= 'macro') "
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6902730699679155"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4O_KSPg-E6O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ba000fe2-58f6-4d5a-8707-dd23f93d4f90"
      },
      "source": [
        "#There was an easier way to just delete stop words by a parameter: \n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "replaced_vector = vectorizer.fit_transform(third_try)\n",
        "replaced_vector_test = vectorizer.transform(newsgroups_test.data)\n",
        "clf3 = MultinomialNB(alpha =0.1)\n",
        "clf3.fit(replaced_vector, train_data['target']) #fit the model with the train data\n",
        "pred10 = clf3.predict(replaced_vector_test)\n",
        "metrics.f1_score(newsgroups_test.target, pred3, average= 'macro')  #use this version "
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7609971497415258"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcYh5MFbkOM4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c2b7795b-f20b-4dc0-a129-c946b24f36b0"
      },
      "source": [
        "print('Original version: ' +str(metrics.f1_score(newsgroups_test.target, pred, average= 'macro') ))\n",
        "print('Deleting stop words: ' + str(metrics.f1_score(newsgroups_test.target, pred10, average= 'macro') ))\n"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original version: 0.7564535630493667\n",
            "Deleting stop words: 0.7609971497415258\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fT076e4AnCo8",
        "colab_type": "text"
      },
      "source": [
        "Deleting stop words is has a better result: use new vectorizer "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w56faPDvhqJw",
        "colab_type": "text"
      },
      "source": [
        "**(3) Try other preprocessing : deleting the email address**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTXlvxAAoWEF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "781c6d39-fdb5-4ab4-83ad-e1d8dee00bc6"
      },
      "source": [
        "#a string that includes a email address\n",
        "newsgroups_train['data'] [30]"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n  Actually, my atheism is based on ignorance.  Ignorance of the\\n  existence of any god.  Don\\'t fall into the \"atheists don\\'t believe\\n  because of their pride\" mistake.\\n\\n\\n/\\\\/\\\\/\\\\/\\\\/\\\\/\\\\/\\\\/\\\\/\\\\/\\\\/\\\\/\\\\/\\\\/\\\\/\\\\/\\\\/\\\\/\\\\/\\\\/\\\\/\\\\/\\\\/\\\\/\\\\/\\\\/\\\\/\\\\/\\\\/\\\\/\\\\/\\\\/\\\\/\\\\/\\\\ \\n\\nBob Beauchaine bobbe@vice.ICO.TEK.COM \\n\\nThey said that Queens could stay, they blew the Bronx away,\\nand sank Manhattan out at sea.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CD6k1OHRoZqn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "b785d551-e368-4e30-a03e-5697c57daca1"
      },
      "source": [
        "#try deleting the address \n",
        "def delete(sent):\n",
        "  sent = re.sub(r'[\\w]+\\@[\\w]+.[\\w]+\\.+[\\w]+\\.+[\\w]+','',sent)\n",
        "  sent = re.sub(r'[\\w]+\\@[\\w]+.[\\w]+\\.*?[\\w]*?\\.*?[\\w]*?','',sent)\n",
        "  sent = re.sub(r'\\b[\\W]\\b',' ',sent) #delete non-word\n",
        "  sent = re.sub(r'\\b\\d+?\\b','',sent) #delete not needed digits \n",
        "  #sent = re.sub(r'\\b\\d+?[\\w]*\\b','',sent) #delete weird digit-word \n",
        "  sent = re.sub(r'\\b\\_+[\\w]*\\b','',sent)\n",
        "  sent = re.sub(r'\\b[\\d]*\\_+\\b','',sent)\n",
        "  return sent\n",
        "\n",
        "delete(newsgroups_train['data'][40]) #works\n",
        "delete(newsgroups_train['data'][30]) #works"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n  Actually, my atheism is based on ignorance.  Ignorance of the\\n  existence of any god.  Don t fall into the \"atheists don t believe\\n  because of their pride\" mistake.\\n\\n\\n/\\\\/\\\\/\\\\/\\\\/\\\\/\\\\/\\\\/\\\\/\\\\/\\\\/\\\\/\\\\/\\\\/\\\\/\\\\/\\\\/\\\\/\\\\/\\\\/\\\\/\\\\/\\\\/\\\\/\\\\/\\\\/\\\\/\\\\/\\\\/\\\\/\\\\/\\\\/\\\\/\\\\/\\\\ \\n\\nBob Beauchaine  \\n\\nThey said that Queens could stay, they blew the Bronx away,\\nand sank Manhattan out at sea.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgfM8kZMq5Kk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ffe4cbd2-5fd8-46dc-a379-904bc5230d37"
      },
      "source": [
        "third_try =[]\n",
        "\n",
        "for sentence in newsgroups_train['data']:\n",
        "  third_try.append(delete(sentence))\n",
        "third_try[40] #now train-data \n"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'As I was created in the image of Gaea, therefore I must be the pinnacle of creation, She which Creates, She which Births, She which Continues.\\n\\nOr, to cut all the religious crap, I m a woman, thanks.\\nAnd it s sexism that started me on the road to atheism.\\n\\n-- \\nMaddi Hausmann                       \\nCentigram Communications Corp        San Jose California    '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dk1KipGorNSc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "06c98a59-d496-47b3-eee6-45723db74cab"
      },
      "source": [
        "train_data['target'] #same target data \n",
        "len(third_try) #2034 elements "
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2034"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vo9bBVgBuk6V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "39090223-fb77-444d-e378-a1a6f48cf297"
      },
      "source": [
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "replaced_vector = vectorizer.fit_transform(third_try)\n",
        "replaced_vector_test = vectorizer.transform(newsgroups_test.data)\n",
        "clf3 = MultinomialNB(alpha =0.1)\n",
        "clf3.fit(replaced_vector, train_data['target']) #fit the model with the train data\n",
        "pred3 = clf3.predict(replaced_vector_test)\n",
        "metrics.f1_score(newsgroups_test.target, pred3, average= 'macro') "
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7609971497415258"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwWKsPepu4o_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "6291486d-cbc1-43ad-da11-33fc1c782c9c"
      },
      "source": [
        "print('Original version: ' +str(metrics.f1_score(newsgroups_test.target, pred, average= 'macro') ))\n",
        "print('Deleting stop words: ' + str(metrics.f1_score(newsgroups_test.target, pred10, average= 'macro') ))\n",
        "print('Deleting email, non-words: ' + str(metrics.f1_score(newsgroups_test.target, pred3, average= 'macro') ))"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original version: 0.7564535630493667\n",
            "Deleting stop words: 0.7609971497415258\n",
            "Deleting email, non-words: 0.7609971497415258\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RI_tBXTu-AV",
        "colab_type": "text"
      },
      "source": [
        "deleting emails is appropriate than leaving them , so ues new dataset \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5F3pB9VQvFcY",
        "colab_type": "text"
      },
      "source": [
        "**(4) Try other model: TF**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOHqhEvYvBWD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ffa7d606-92fa-4f75-c3d6-ce2558eca3e9"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "tfvectorizer = CountVectorizer(stop_words='english')\n",
        "tf_vect = tfvectorizer.fit_transform(third_try) #used email deleted data \n",
        "\n",
        "tf_vect_test = tfvectorizer.transform(newsgroups_test.data)\n",
        "clf4 = MultinomialNB(alpha =0.1)\n",
        "clf4.fit(tf_vect, train_data['target']) #fit the model with the train data\n",
        "pred4 = clf4.predict(tf_vect_test)\n",
        "metrics.f1_score(newsgroups_test.target, pred4, average= 'macro') \n"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.767115194879272"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtPgrGDtzPqB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4ddce9e3-7019-4bee-b0ee-457ec1439e72"
      },
      "source": [
        "tfvectorizer2 = CountVectorizer(binary=True, stop_words='english') #unigram/bigram \n",
        "\n",
        "tf_vect2 = tfvectorizer2.fit_transform(third_try) #used email deleted data \n",
        "\n",
        "tf_vect_test2 = tfvectorizer.transform(newsgroups_test.data)\n",
        "clf5= MultinomialNB(alpha =0.1)\n",
        "clf5.fit(tf_vect2, train_data['target']) #fit the model with the train data\n",
        "pred5 = clf5.predict(tf_vect_test2)\n",
        "metrics.f1_score(newsgroups_test.target, pred5, average= 'macro') \n"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7654156497733925"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0o7X2PTzKXH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "87728655-7cd6-475c-f1ab-6ba0790575b0"
      },
      "source": [
        "print('Original version: ' +str(metrics.f1_score(newsgroups_test.target, pred, average= 'macro') ))\n",
        "print('Deleting stop words: ' + str(metrics.f1_score(newsgroups_test.target, pred10, average= 'macro') ))\n",
        "print('Deleting email, non-words: ' + str(metrics.f1_score(newsgroups_test.target, pred3, average= 'macro') ))\n",
        "print('Using TF: '+ str(metrics.f1_score(newsgroups_test.target, pred4, average= 'macro') ))\n",
        "print('Using TF binary encoding (one hot encoding): '+ str(metrics.f1_score(newsgroups_test.target, pred5, average= 'macro') ))"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original version: 0.7564535630493667\n",
            "Deleting stop words: 0.7609971497415258\n",
            "Deleting email, non-words: 0.7609971497415258\n",
            "Using TF: 0.767115194879272\n",
            "Using TF binary encoding (one hot encoding): 0.7654156497733925\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dli0FxlP0TeM",
        "colab_type": "text"
      },
      "source": [
        "**(5) NEW MODEL: Logistic Regression**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vagObiyy0cNq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Cleaning the datasets with nice names\n",
        "new_test = newsgroups_test.data\n",
        "new_train = third_try #train data (list of words)\n",
        "vector_train = tf_vect #vector made by train set using tf: appearance of word \n",
        "vector_test = tf_vect_test #vector made by test set using replaced_vector \n",
        "new_train_y = train_data['target'] #labels of train data \n",
        "new_test_y =newsgroups_test.target #label of test data \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZU4qow68ozd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d8797eb9-98ce-4b43-f94f-6551e3716326"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(vector_train, new_train_y)\n",
        "predictions = model.predict(vector_test)\n",
        "metrics.f1_score(new_test_y, predictions, average= 'macro') "
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7105273272621087"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odIVws8NBnJ1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "37f2b43f-bb2d-4c9b-d65d-0bb627d4afed"
      },
      "source": [
        "print('Original version: ' +str(metrics.f1_score(newsgroups_test.target, pred, average= 'macro') ))\n",
        "print('Deleting stop words: ' + str(metrics.f1_score(newsgroups_test.target, pred10, average= 'macro') ))\n",
        "print('Deleting email, non-words: ' + str(metrics.f1_score(newsgroups_test.target, pred3, average= 'macro') ))\n",
        "print('Using TF: '+ str(metrics.f1_score(newsgroups_test.target, pred4, average= 'macro') ))\n",
        "print('Using TF binary encoding (one hot encoding): '+ str(metrics.f1_score(newsgroups_test.target, pred5, average= 'macro') ))\n",
        "print('------Now using, TF vector matrix for modeling-------')\n",
        "print('Using logistic regression : '+ str(metrics.f1_score(newsgroups_test.target, predictions, average= 'macro') ))"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original version: 0.7564535630493667\n",
            "Deleting stop words: 0.7609971497415258\n",
            "Deleting email, non-words: 0.7609971497415258\n",
            "Using TF: 0.767115194879272\n",
            "Using TF binary encoding (one hot encoding): 0.7654156497733925\n",
            "------Now using, TF vector matrix for modeling-------\n",
            "Using logistic regression : 0.7105273272621087\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Q3HPelkCQxi",
        "colab_type": "text"
      },
      "source": [
        "**(6) NEW MODEL: KNN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bon9F7xBznR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1331912f-3df9-41a6-9415-c0183a775fc5"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "model = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "\n",
        "model.fit(vector_train,new_train_y)\n",
        "\n",
        "\n",
        "predicted= model.predict(vector_test) \n",
        "metrics.f1_score(new_test_y, predicted, average= 'macro') #has bad f1 score \n"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3540099646415944"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7XmYUblB2lq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "7b2f8df9-4f46-479b-c8dc-c9f786c9f7f5"
      },
      "source": [
        "print('Original version: ' +str(metrics.f1_score(newsgroups_test.target, pred, average= 'macro') ))\n",
        "print('Deleting stop words: ' + str(metrics.f1_score(newsgroups_test.target, pred10, average= 'macro') ))\n",
        "print('Deleting email, non-words: ' + str(metrics.f1_score(newsgroups_test.target, pred3, average= 'macro') ))\n",
        "print('Using TF: '+ str(metrics.f1_score(newsgroups_test.target, pred4, average= 'macro') ))\n",
        "print('Using TF binary encoding (one hot encoding): '+ str(metrics.f1_score(newsgroups_test.target, pred5, average= 'macro') ))\n",
        "print('------Now using, TF vector matrix for modeling-------')\n",
        "print('Using logistic regression : '+ str(metrics.f1_score(newsgroups_test.target, predictions, average= 'macro') ))\n",
        "print('Using KNN : '+ str(metrics.f1_score(newsgroups_test.target, predicted, average= 'macro') ))"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original version: 0.7564535630493667\n",
            "Deleting stop words: 0.7609971497415258\n",
            "Deleting email, non-words: 0.7609971497415258\n",
            "Using TF: 0.767115194879272\n",
            "Using TF binary encoding (one hot encoding): 0.7654156497733925\n",
            "------Now using, TF vector matrix for modeling-------\n",
            "Using logistic regression : 0.7105273272621087\n",
            "Using KNN : 0.3540099646415944\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfCqZelxDxVK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "47b08620-95a5-4b9a-9862-abbb1cfe1694"
      },
      "source": [
        "from sklearn import svm\n",
        "\n",
        "\n",
        "SVM = svm.SVC()\n",
        "SVM.fit(vector_train,new_train_y)\n",
        "\n",
        "predicts= SVM.predict(vector_test) \n",
        "metrics.f1_score(new_test_y, predicts, average= 'macro') #has not good f1 score \n"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5510312967096778"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QONkLD6DEFFl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "07ef5e98-e4fc-4c31-e984-06c51f059692"
      },
      "source": [
        "print('Original version: ' +str(metrics.f1_score(newsgroups_test.target, pred, average= 'macro') ))\n",
        "print('Deleting stop words: ' + str(metrics.f1_score(newsgroups_test.target, pred10, average= 'macro') ))\n",
        "print('Deleting email, non-words: ' + str(metrics.f1_score(newsgroups_test.target, pred3, average= 'macro') ))\n",
        "print('Using TF: '+ str(metrics.f1_score(newsgroups_test.target, pred4, average= 'macro') ))\n",
        "print('Using TF binary encoding (one hot encoding): '+ str(metrics.f1_score(newsgroups_test.target, pred5, average= 'macro') ))\n",
        "print('------Now using, TF vector matrix for modeling-------')\n",
        "print('Using logistic regression : '+ str(metrics.f1_score(newsgroups_test.target, predictions, average= 'macro') ))\n",
        "print('Using KNN : '+ str(metrics.f1_score(newsgroups_test.target, predicted, average= 'macro') ))\n",
        "print('Using SVM : '+ str(metrics.f1_score(newsgroups_test.target, predicts, average= 'macro') ))"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original version: 0.7564535630493667\n",
            "Deleting stop words: 0.7609971497415258\n",
            "Deleting email, non-words: 0.7609971497415258\n",
            "Using TF: 0.767115194879272\n",
            "Using TF binary encoding (one hot encoding): 0.7654156497733925\n",
            "------Now using, TF vector matrix for modeling-------\n",
            "Using logistic regression : 0.7105273272621087\n",
            "Using KNN : 0.3540099646415944\n",
            "Using SVM : 0.5510312967096778\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwjmNmFTFHns",
        "colab_type": "text"
      },
      "source": [
        "**(7) NEW MODEL: TREE CLASSIFIER **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4VnwuMsFPEg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c6ddc59a-b889-48b2-fd6f-5aaaed0e82d8"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import tree\n",
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(vector_train,new_train_y)\n",
        "\n",
        "predict= dt.predict(vector_test) \n",
        "metrics.f1_score(new_test_y, predict, average= 'macro') #has not good f1 score "
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5722461332824256"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fy2ZV4b9FPkA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "ef1b68c4-7725-4b19-a1d5-f17ce8a03f4a"
      },
      "source": [
        "print('Original version: ' +str(metrics.f1_score(newsgroups_test.target, pred, average= 'macro') ))\n",
        "print('Deleting stop words: ' + str(metrics.f1_score(newsgroups_test.target, pred10, average= 'macro') ))\n",
        "print('Deleting email, non-words: ' + str(metrics.f1_score(newsgroups_test.target, pred3, average= 'macro') ))\n",
        "print('Using TF: '+ str(metrics.f1_score(newsgroups_test.target, pred4, average= 'macro') ))\n",
        "print('Using TF binary encoding (one hot encoding): '+ str(metrics.f1_score(newsgroups_test.target, pred5, average= 'macro') ))\n",
        "print('------Now using, TF vector matrix for modeling-------')\n",
        "print('Using logistic regression : '+ str(metrics.f1_score(newsgroups_test.target, predictions, average= 'macro') ))\n",
        "print('Using KNN : '+ str(metrics.f1_score(newsgroups_test.target, predicted, average= 'macro') ))\n",
        "print('Using SVM : '+ str(metrics.f1_score(newsgroups_test.target, predicts, average= 'macro') ))\n",
        "print('Using Decision-Tree  : '+ str(metrics.f1_score(newsgroups_test.target, predict, average= 'macro') ))\n"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original version: 0.7564535630493667\n",
            "Deleting stop words: 0.7609971497415258\n",
            "Deleting email, non-words: 0.7609971497415258\n",
            "Using TF: 0.767115194879272\n",
            "Using TF binary encoding (one hot encoding): 0.7654156497733925\n",
            "------Now using, TF vector matrix for modeling-------\n",
            "Using logistic regression : 0.7105273272621087\n",
            "Using KNN : 0.3540099646415944\n",
            "Using SVM : 0.5510312967096778\n",
            "Using Decision-Tree  : 0.5722461332824256\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzp0DjjJEIPX",
        "colab_type": "text"
      },
      "source": [
        "When using better parameters, or doing some greed search each model may get better f-1 scores\n",
        "(In this example, I only used the default values for the modeling)\n"
      ]
    }
  ]
}