{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "최재영_2016312411_0.65 .ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLeQfpHELPkx",
        "colab_type": "text"
      },
      "source": [
        "## FINAL EXAM ANALYSIS "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UA6bcfrmLNW_",
        "colab_type": "text"
      },
      "source": [
        "# **(1) Loading the Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKgFb-KfJ7Om",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install konlpy\n",
        "import pandas as pd\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyiibC-KLWLl",
        "colab_type": "text"
      },
      "source": [
        "# **(+1) Before preprocessing; EDA**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZCmhbJXLYeq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "2529b378-9ceb-4d10-aed5-46e78f484d5e"
      },
      "source": [
        "train = pd.read_csv('train_data.csv')\n",
        "test = pd.read_csv('test_data.csv')\n",
        "train.head() #category, content, title \n",
        "test.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>content</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>육아/교육</td>\n",
              "      <td>세 자녀 이상을 둔 다자녀 가정의 경우 대학생 국가장학금 제도 개편이 정말 시급합니...</td>\n",
              "      <td>다자녀 가정 대학 국가장학금 제도 개선해 주세요</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>정치개혁</td>\n",
              "      <td>국민을위해 국민을위한다면 정말 대한민국을 위한다면 자리에 연연하지마시고 그만 내려오세요</td>\n",
              "      <td>조국, 이재명, 임종석, 탁현민, 유은혜 이제 자리에서 그만 내려오세요</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>정치개혁</td>\n",
              "      <td>공무원은 죄가잇으면 처벌안합니가 업무상 죄가있으면 두배세배 처벌해야 되야되는거아닙니...</td>\n",
              "      <td>촛불은 힘있고 권력있는자 아니면 공무원을 위한촛불입니까</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>인권/성평등</td>\n",
              "      <td>현재 사회에서 가장 이슈가 되는것이 남녀간의 갈등이 가장 큰 이슈인걸 알고 있을실거...</td>\n",
              "      <td>남녀간의 갈등 대한민국 남성은 노예?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>정치개혁</td>\n",
              "      <td>문재인 대통령이 전정부 채동욱 전검찰총장 해임에 강력히 반발하던 특정지역 윤석열을 ...</td>\n",
              "      <td>공정수사을 위하여 윤석열 파면 하세요</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  category  ...                                    title\n",
              "0    육아/교육  ...               다자녀 가정 대학 국가장학금 제도 개선해 주세요\n",
              "1     정치개혁  ...  조국, 이재명, 임종석, 탁현민, 유은혜 이제 자리에서 그만 내려오세요\n",
              "2     정치개혁  ...           촛불은 힘있고 권력있는자 아니면 공무원을 위한촛불입니까\n",
              "3   인권/성평등  ...                     남녀간의 갈등 대한민국 남성은 노예?\n",
              "4     정치개혁  ...                     공정수사을 위하여 윤석열 파면 하세요\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEED-imWLyc0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "e708b631-59f1-4ef9-bbc7-b768b6aa12b0"
      },
      "source": [
        "#check for nan values \n",
        "train.isnull().sum()\n",
        "test.isnull().sum() \n",
        "# #there are no null values in the dataset \n",
        "len(train) #10686\n",
        "len(test) #1158"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1158"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNXTZEnRL_WI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "outputId": "24c65cc0-763e-46ae-b8c2-6e3179c81d27"
      },
      "source": [
        "#check for duplicates \n",
        "train[train['title'].duplicated()] #562 rows \n",
        "#there are duplicates in the titles  -> but content are somewhat different \n",
        "train[train['content'].duplicated()] #384 rows \n",
        "#duplicates in the content too -> different titles \n",
        "\n",
        "train[train[['content', 'title']].duplicated()].head(20) #247 rows that have same title and content -> delete these ! \n",
        "\n",
        "train.drop_duplicates(subset=['content', 'title'], inplace=True) #drop duplicates in the dataset \n",
        "len(train) #10439\n",
        "train.head(10)\n",
        "# train[train[['content', 'title']].duplicated()] #no more duplicates "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>content</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>정치개혁</td>\n",
              "      <td>문통, 직접 민의를 살피지 않고 권력의 권좌에 앉아 보고만 받고 권력의 힘만 누렸으...</td>\n",
              "      <td>문통, 직접 민의를 살피지 않고 보고에만 의존하였으니 이젠 가망이 없소!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>육아/교육</td>\n",
              "      <td>초등학교 내 학부형 모임인 ‘아버지회’ 의 문제점을 제기하고자 합니다. 초등학교 내...</td>\n",
              "      <td>뇌물수수, 청탁이 만연하는 초등학교 아버지회를 없애주세요</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>보건복지</td>\n",
              "      <td>주변을 둘러보면 생활이 어렵지만 기초생활수급자 자격요건에 해당되지 않아 지원을 받지...</td>\n",
              "      <td>기초생활수급자 자격요건을 확대해주세요</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>경제민주화</td>\n",
              "      <td>거래소 노조 \"시감위원장 금융위 낙하산 인사 중단하라\" 한국거래소 노조는 현재 진행...</td>\n",
              "      <td>문재인 대통령님 시장감시위원장 인선과 관련해 금융위원회 낙하산 인사를 즉각 중단하십시요.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>육아/교육</td>\n",
              "      <td>안녕하세요 서울시 송파구 풍납2동 OOOO어린이집 보낸 김OO(여), 정OO(남)아...</td>\n",
              "      <td>저희아이들이 어린이집서 학대를 당했습니다. 어린이집 아동학대 피해아동 구제해 주세요.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>보건복지</td>\n",
              "      <td>치매병원에 어머니를 입원 시킨 가족입니다. 병원비가 적지 않게 들어요 정부 초창기 ...</td>\n",
              "      <td>치매가족 지원</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>인권/성평등</td>\n",
              "      <td>가해자에게만 유리한 법 성범죄 공소시효를 폐지시켜 주세요. 가해자와 피해자를 동등한...</td>\n",
              "      <td>성범죄 공소시효를 폐지시켜 주십시요.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>인권/성평등</td>\n",
              "      <td>FC서울의 응원단들은 타 팀들의 응원단에 많은 패를 끼친다. 그들은 먼저 다른 응원...</td>\n",
              "      <td>FC서울 타나토스, 수호신 등 해체</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>보건복지</td>\n",
              "      <td>미세먼지 마스크 개봉시 심한 역한 냄새가 나는것이 점점 늘어나고 있으며 형광물질은 ...</td>\n",
              "      <td>미세먼지 마스크 유해성/안전성 믿고 써도 되나요?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>육아/교육</td>\n",
              "      <td>청소년에대한 방송을보고 교육하는교장이나 경찰등이 대처하는 방법에 대해서 화가 너무납...</td>\n",
              "      <td>그것이 알고싶다를보고 너무 화가나서 청원함</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  category  ...                                              title\n",
              "0     정치개혁  ...           문통, 직접 민의를 살피지 않고 보고에만 의존하였으니 이젠 가망이 없소!\n",
              "1    육아/교육  ...                    뇌물수수, 청탁이 만연하는 초등학교 아버지회를 없애주세요\n",
              "2     보건복지  ...                               기초생활수급자 자격요건을 확대해주세요\n",
              "3    경제민주화  ...  문재인 대통령님 시장감시위원장 인선과 관련해 금융위원회 낙하산 인사를 즉각 중단하십시요.\n",
              "4    육아/교육  ...    저희아이들이 어린이집서 학대를 당했습니다. 어린이집 아동학대 피해아동 구제해 주세요.\n",
              "5     보건복지  ...                                            치매가족 지원\n",
              "6   인권/성평등  ...                               성범죄 공소시효를 폐지시켜 주십시요.\n",
              "7   인권/성평등  ...                                FC서울 타나토스, 수호신 등 해체\n",
              "8     보건복지  ...                        미세먼지 마스크 유해성/안전성 믿고 써도 되나요?\n",
              "9    육아/교육  ...                            그것이 알고싶다를보고 너무 화가나서 청원함\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ls4_uzAJNvVc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "edfaa41e-b6dc-4282-88e3-cdee243d9e00"
      },
      "source": [
        "#check labels \n",
        "train['category'].value_counts().plot(kind = 'bar')  #한글이라 깨지지만 폰트 설정하면 된당"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fa25a5e5588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51221 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 52824 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 44060 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 54785 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 44368 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 53685 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 44148 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 52629 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 44397 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 53664 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51068 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51088 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 47532 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51064 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 44428 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 49457 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 54217 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 46321 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 44221 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51228 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 48124 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51452 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 54868 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 48372 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 48373 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51648 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 50977 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 50500 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51221 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 52824 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 44060 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 54785 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 44368 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 53685 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 44148 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 52629 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 44397 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 53664 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51068 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51088 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 47532 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51064 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 44428 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 49457 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 54217 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 46321 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 44221 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51228 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 48124 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51452 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 54868 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 48372 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 48373 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51648 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 50977 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 50500 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtd1vPDbOMlB",
        "colab_type": "text"
      },
      "source": [
        "# **(2) Preprocessing the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsL6kMUlPXkM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "2cde7832-9df2-4652-f506-5d7b0af5b7d8"
      },
      "source": [
        "#use both content and title for text processing  --> add up both columns \n",
        "\n",
        "train['text'] = train['title']+' '+ train['content'] \n",
        "train.head()\n",
        "\n",
        "\n",
        "test['text'] = test['title']+' '+ test['content'] \n",
        "test.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>content</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>육아/교육</td>\n",
              "      <td>세 자녀 이상을 둔 다자녀 가정의 경우 대학생 국가장학금 제도 개편이 정말 시급합니...</td>\n",
              "      <td>다자녀 가정 대학 국가장학금 제도 개선해 주세요</td>\n",
              "      <td>다자녀 가정 대학 국가장학금 제도 개선해 주세요 세 자녀 이상을 둔 다자녀 가정의 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>정치개혁</td>\n",
              "      <td>국민을위해 국민을위한다면 정말 대한민국을 위한다면 자리에 연연하지마시고 그만 내려오세요</td>\n",
              "      <td>조국, 이재명, 임종석, 탁현민, 유은혜 이제 자리에서 그만 내려오세요</td>\n",
              "      <td>조국, 이재명, 임종석, 탁현민, 유은혜 이제 자리에서 그만 내려오세요 국민을위해 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>정치개혁</td>\n",
              "      <td>공무원은 죄가잇으면 처벌안합니가 업무상 죄가있으면 두배세배 처벌해야 되야되는거아닙니...</td>\n",
              "      <td>촛불은 힘있고 권력있는자 아니면 공무원을 위한촛불입니까</td>\n",
              "      <td>촛불은 힘있고 권력있는자 아니면 공무원을 위한촛불입니까 공무원은 죄가잇으면 처벌안합...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>인권/성평등</td>\n",
              "      <td>현재 사회에서 가장 이슈가 되는것이 남녀간의 갈등이 가장 큰 이슈인걸 알고 있을실거...</td>\n",
              "      <td>남녀간의 갈등 대한민국 남성은 노예?</td>\n",
              "      <td>남녀간의 갈등 대한민국 남성은 노예? 현재 사회에서 가장 이슈가 되는것이 남녀간의 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>정치개혁</td>\n",
              "      <td>문재인 대통령이 전정부 채동욱 전검찰총장 해임에 강력히 반발하던 특정지역 윤석열을 ...</td>\n",
              "      <td>공정수사을 위하여 윤석열 파면 하세요</td>\n",
              "      <td>공정수사을 위하여 윤석열 파면 하세요 문재인 대통령이 전정부 채동욱 전검찰총장 해임...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  category  ...                                               text\n",
              "0    육아/교육  ...  다자녀 가정 대학 국가장학금 제도 개선해 주세요 세 자녀 이상을 둔 다자녀 가정의 ...\n",
              "1     정치개혁  ...  조국, 이재명, 임종석, 탁현민, 유은혜 이제 자리에서 그만 내려오세요 국민을위해 ...\n",
              "2     정치개혁  ...  촛불은 힘있고 권력있는자 아니면 공무원을 위한촛불입니까 공무원은 죄가잇으면 처벌안합...\n",
              "3   인권/성평등  ...  남녀간의 갈등 대한민국 남성은 노예? 현재 사회에서 가장 이슈가 되는것이 남녀간의 ...\n",
              "4     정치개혁  ...  공정수사을 위하여 윤석열 파면 하세요 문재인 대통령이 전정부 채동욱 전검찰총장 해임...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLg-UGA4OGQd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "outputId": "0c7ad4bb-9227-4de8-83d8-cdda4eb7ffa7"
      },
      "source": [
        "import re   \n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def preprocess_data(train, test,content): \n",
        "\n",
        "  #cleaning the train_x  \n",
        "  train[content] = train[content].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣]\",\"\") #글자외의 문자 삭제 \n",
        "  train.replace('', np.nan, inplace=True) #특수문자로 이루어졌던 후기의 경우 -> nan으로 표기 \n",
        "  train=train.dropna(how = 'any') #nan 데이터 삭제하기 \n",
        "\n",
        "  #cleaning the test_x  \n",
        "  test[content] = test[content].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\") #글자 외의 문자 삭제 \n",
        "  test.replace('', np.nan, inplace=True) #특수문자로 이루어졌던 후기의 경우 -> nan으로 표기 \n",
        "  test=test.dropna(how = 'any') #nan 데이터 삭제하기 \n",
        "\n",
        "\n",
        "  #make sure no nan is in the dataset for vectorization \n",
        "  return train,test\n",
        "\n",
        "train,test = preprocess_data(train, test,'title')\n",
        "\n",
        "train.head(10)\n",
        "test.head(10)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>content</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>육아/교육</td>\n",
              "      <td>세 자녀 이상을 둔 다자녀 가정의 경우 대학생 국가장학금 제도 개편이 정말 시급합니...</td>\n",
              "      <td>다자녀 가정 대학 국가장학금 제도 개선해 주세요</td>\n",
              "      <td>다자녀 가정 대학 국가장학금 제도 개선해 주세요 세 자녀 이상을 둔 다자녀 가정의 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>정치개혁</td>\n",
              "      <td>국민을위해 국민을위한다면 정말 대한민국을 위한다면 자리에 연연하지마시고 그만 내려오세요</td>\n",
              "      <td>조국 이재명 임종석 탁현민 유은혜 이제 자리에서 그만 내려오세요</td>\n",
              "      <td>조국, 이재명, 임종석, 탁현민, 유은혜 이제 자리에서 그만 내려오세요 국민을위해 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>정치개혁</td>\n",
              "      <td>공무원은 죄가잇으면 처벌안합니가 업무상 죄가있으면 두배세배 처벌해야 되야되는거아닙니...</td>\n",
              "      <td>촛불은 힘있고 권력있는자 아니면 공무원을 위한촛불입니까</td>\n",
              "      <td>촛불은 힘있고 권력있는자 아니면 공무원을 위한촛불입니까 공무원은 죄가잇으면 처벌안합...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>인권/성평등</td>\n",
              "      <td>현재 사회에서 가장 이슈가 되는것이 남녀간의 갈등이 가장 큰 이슈인걸 알고 있을실거...</td>\n",
              "      <td>남녀간의 갈등 대한민국 남성은 노예</td>\n",
              "      <td>남녀간의 갈등 대한민국 남성은 노예? 현재 사회에서 가장 이슈가 되는것이 남녀간의 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>정치개혁</td>\n",
              "      <td>문재인 대통령이 전정부 채동욱 전검찰총장 해임에 강력히 반발하던 특정지역 윤석열을 ...</td>\n",
              "      <td>공정수사을 위하여 윤석열 파면 하세요</td>\n",
              "      <td>공정수사을 위하여 윤석열 파면 하세요 문재인 대통령이 전정부 채동욱 전검찰총장 해임...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>육아/교육</td>\n",
              "      <td>유치원3법 다좋습니다 병설유치원은 많지 않고 어쩔수없어 사립으로가는경우도 많습니다 ...</td>\n",
              "      <td>유치원법</td>\n",
              "      <td>유치원3법 유치원3법 다좋습니다 병설유치원은 많지 않고 어쩔수없어 사립으로가는경우도...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>보건복지</td>\n",
              "      <td>100세 시대 노인이 많은 나라! 집에서 어른들을 간호할 여력이 되지 않고 요양병원...</td>\n",
              "      <td>노인 요양병원 대소변 일괄처리 어떻게 생각하세요</td>\n",
              "      <td>노인 요양병원 대소변 일괄처리 어떻게 생각하세요? 100세 시대 노인이 많은 나라!...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>경제민주화</td>\n",
              "      <td>살려 주세요! 경남제약 상폐 되면 저희 가족 위기에서 벗어 날수가 없습니다! 착곡 ...</td>\n",
              "      <td>경남제약  상폐  철회  해  주세요</td>\n",
              "      <td>경남제약  상폐  철회  해  주세요 살려 주세요! 경남제약 상폐 되면 저희 가족 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>보건복지</td>\n",
              "      <td>아무리 외쳐보고 국민연금 공단에 전화를 해도 똑 같은 답 77조 노후 공적자금 참 ...</td>\n",
              "      <td>국민연금 힘든 국민들 묶어  놓고  외면하는가</td>\n",
              "      <td>국민연금 힘든 국민들 묶어  놓고  외면하는가 아무리 외쳐보고 국민연금 공단에 전화...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>교통/건축/국토</td>\n",
              "      <td>아파트 층간소음으로 폭행에 살인으로 이어지는 기사가 이어지고 있습니다. 아파트 거실...</td>\n",
              "      <td>아파트 층간소음 건설사에서 고쳐주든지 배상하게 해주세요</td>\n",
              "      <td>아파트 층간소음 건설사에서 고쳐주든지 배상하게 해주세요 아파트 층간소음으로 폭행에 ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   category  ...                                               text\n",
              "0     육아/교육  ...  다자녀 가정 대학 국가장학금 제도 개선해 주세요 세 자녀 이상을 둔 다자녀 가정의 ...\n",
              "1      정치개혁  ...  조국, 이재명, 임종석, 탁현민, 유은혜 이제 자리에서 그만 내려오세요 국민을위해 ...\n",
              "2      정치개혁  ...  촛불은 힘있고 권력있는자 아니면 공무원을 위한촛불입니까 공무원은 죄가잇으면 처벌안합...\n",
              "3    인권/성평등  ...  남녀간의 갈등 대한민국 남성은 노예? 현재 사회에서 가장 이슈가 되는것이 남녀간의 ...\n",
              "4      정치개혁  ...  공정수사을 위하여 윤석열 파면 하세요 문재인 대통령이 전정부 채동욱 전검찰총장 해임...\n",
              "5     육아/교육  ...  유치원3법 유치원3법 다좋습니다 병설유치원은 많지 않고 어쩔수없어 사립으로가는경우도...\n",
              "6      보건복지  ...  노인 요양병원 대소변 일괄처리 어떻게 생각하세요? 100세 시대 노인이 많은 나라!...\n",
              "7     경제민주화  ...  경남제약  상폐  철회  해  주세요 살려 주세요! 경남제약 상폐 되면 저희 가족 ...\n",
              "8      보건복지  ...  국민연금 힘든 국민들 묶어  놓고  외면하는가 아무리 외쳐보고 국민연금 공단에 전화...\n",
              "9  교통/건축/국토  ...  아파트 층간소음 건설사에서 고쳐주든지 배상하게 해주세요 아파트 층간소음으로 폭행에 ...\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bi8djsY_P_RC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "outputId": "a49e6ce1-8eeb-4374-a20f-02fdeca3127a"
      },
      "source": [
        "#split the dataset into train, val, test \n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "def split_data(train,test,condition):\n",
        "\n",
        "  #split the dataset into train/validation set \n",
        "  train, validation = train_test_split(train, test_size =.2 , random_state = 123)\n",
        "  train_x , train_y = train[condition], train['category']\n",
        "  test_x, test_y  = test[condition] , test['category']\n",
        "  val_x, val_y = validation[condition], validation['category']\n",
        "\n",
        "  return train_x , train_y, test_x, test_y , val_x, val_y\n",
        "\n",
        "train_x , train_y, test_x, test_y , val_x, val_y= split_data(train,test,'title') #title 만 이용한다 시간이 너무 오래걸리기때문에 \n",
        "#if we have time we can use text to preprocess and split ; text : lots of words so takes a long time to preprocess the dataset\n",
        "train_x.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9898     경제민주화\n",
              "984      경제민주화\n",
              "3022      보건복지\n",
              "8648      정치개혁\n",
              "10137      일자리\n",
              "Name: category, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPHuOJs2QUQL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "aca7e183-1385-40c2-aec1-a7ed6b730d78"
      },
      "source": [
        "#one hot encode the categories \n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "onehot = OneHotEncoder()\n",
        "train_y=np.array(train_y).reshape(-1,1)\n",
        "test_y=np.array(test_y).reshape(-1,1)\n",
        "val_y=np.array(val_y).reshape(-1,1)\n",
        "\n",
        "\n",
        "\n",
        "onehot.fit(train_y)\n",
        "train_y_onehot = onehot.transform(train_y).toarray()\n",
        "test_y_onehot = onehot.transform(test_y).toarray()\n",
        "val_y_onehot = onehot.transform(val_y).toarray()\n",
        "\n",
        "val_y_onehot[:10]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLlpGD5FTz7Q",
        "colab_type": "text"
      },
      "source": [
        "# **(3) TOKENIZING the dataset**\n",
        "\n",
        "-make a list of lists (tokens of words)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fW8uDIfaTucH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 905
        },
        "outputId": "ca5d37f3-926c-499a-84e5-732943cf7556"
      },
      "source": [
        "\n",
        "from konlpy.tag import Hannanum, Kkma, Komoran, Okt \n",
        "\n",
        "#different vectorizations \n",
        "okt=Okt()  \n",
        "hannanum= Hannanum()\n",
        "kkma =Kkma()\n",
        "komoran =Komoran()\n",
        "\n",
        "#self made stopwords \n",
        "stopwords = ['의','가','이','은','들','는','을','좀','잘','걍','과','도','를','으로','자','에','와','한','하다','주세요','하세요','하자','드립니다','합니다','하라','입니다','있다' ]\n",
        "\n",
        "\n",
        "def tokenize_dataset(train_x,test_x,val_x):\n",
        "\n",
        "  X_train = [] \n",
        "  for sentence in train_x:\n",
        "    temp_X = []\n",
        "    temp_X = okt.morphs(sentence, stem=True) #words in a list \n",
        "    # temp_X = hannanum.morphs(sentence,stem=True)\n",
        "    # temp_X = kkma.morphs(sentence,stem=True)\n",
        "    # temp_X = komoran.morphs(sentence,stem=True)\n",
        "    temp_X = [word for word in temp_X if not word in stopwords] #delete's stopwords \n",
        "    X_train.append(temp_X) #append to new list \n",
        "    # print(temp_X)\n",
        "\n",
        "  print('Train_done')\n",
        "\n",
        "\n",
        "  X_val = [] \n",
        "  for sentence in val_x:\n",
        "    temp_X = []\n",
        "    temp_X = okt.morphs(sentence, stem=True) #words in a list \n",
        "    # temp_X = hannanum.morphs(sentence,stem=True)\n",
        "    # temp_X = kkma.morphs(sentence,stem=True)\n",
        "    # temp_X = komoran.morphs(sentence,stem=True)\n",
        "    temp_X = [word for word in temp_X if not word in stopwords] #delete's stopwords \n",
        "    X_val.append(temp_X) #append to new list \n",
        "\n",
        "\n",
        "  print('Validation_done')\n",
        "  \n",
        "\n",
        "  X_test = [] \n",
        "  for sentence in test_x:\n",
        "    temp_X = []\n",
        "    temp_X = okt.morphs(sentence, stem=True) #words in a list \n",
        "    # temp_X = hannanum.morphs(sentence,stem=True)\n",
        "    # temp_X = kkma.morphs(sentence,stem=True)\n",
        "    # temp_X = komoran.morphs(sentence,stem=True)\n",
        "    temp_X = [word for word in temp_X if not word in stopwords] #delete's stopwords \n",
        "    X_test.append(temp_X) #append to new list \n",
        "\n",
        "  print('Test_done')\n",
        "  return X_train, X_test, X_val\n",
        "\n",
        "X_train, X_test, X_val= tokenize_dataset(train_x,test_x,val_x)\n",
        "\n",
        "X_train[:10]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train_done\n",
            "Validation_done\n",
            "Test_done\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['거래소', '부당하다', '경남', '제약', '죽이다'],\n",
              " ['무주', '대', '신혼부부', '자살', '사건'],\n",
              " ['다른',\n",
              "  '말',\n",
              "  '필요없다',\n",
              "  '국민',\n",
              "  '에게',\n",
              "  '일체',\n",
              "  '도움',\n",
              "  '안되다',\n",
              "  '오히려',\n",
              "  '화',\n",
              "  '만',\n",
              "  '돋다',\n",
              "  '국회',\n",
              "  '필요없다'],\n",
              " ['어린이집', '에서', '장애', '아', '동', '차별', '못', '해주다'],\n",
              " ['내',\n",
              "  '년도',\n",
              "  '우리',\n",
              "  '경제',\n",
              "  '체질개선',\n",
              "  '과활',\n",
              "  '력',\n",
              "  '높이다',\n",
              "  '위해',\n",
              "  '서',\n",
              "  '라도',\n",
              "  '경남',\n",
              "  '제약',\n",
              "  '살리다'],\n",
              " ['피해',\n",
              "  '가족',\n",
              "  '에게',\n",
              "  '억',\n",
              "  '요',\n",
              "  '구',\n",
              "  '어린이집',\n",
              "  '문제',\n",
              "  '어린이집',\n",
              "  '간판',\n",
              "  '바꾸다',\n",
              "  '운영',\n",
              "  '하',\n",
              "  '지',\n",
              "  '못',\n",
              "  '해주다'],\n",
              " ['문재인', '탄핵', '하고', '이낙연', '대통령', '뽑다'],\n",
              " ['문재인', '정부', '경', '제', '정의', '사망', '신고'],\n",
              " ['여성폭력', '방지', '기본', '법', '반대'],\n",
              " ['부유세', '만들다']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlbn4aVfUeyT",
        "colab_type": "text"
      },
      "source": [
        "# **(4) VECTORIZING dataset**\n",
        "\n",
        "-use BOX: tf-idf, tf ,onehotencoding ->차원이 매우 크다는 단점 \n",
        "\n",
        ":make the tokens into a int-tokened data (정수 인코딩) \n",
        "\n",
        "-use word2vec (self trained matrix)\n",
        "\n",
        "-use embedding layer(Embedding()) \n",
        "\n",
        "-use pretrained embedding matrix\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afq3ZAQ4Zwoc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "b50460a1-8eca-4c50-f5f2-a5430fb7a09d"
      },
      "source": [
        "# #what should we use for the length of the size (using text: max is 8691 but this is too big)\n",
        "\n",
        "# total_list = list(X_train) + list(X_val) + list(X_test)\n",
        "#   # print(total_list[:10])\n",
        "\n",
        "# cnt= []\n",
        "# for i in range(0, len(total_list)):\n",
        "#   cnt.append(len(total_list[i]))\n",
        "\n",
        "# a = np.array(cnt)\n",
        "# cnt.sort()\n",
        "# sum(cnt) / len(cnt) #the mean is 165 \n",
        "\n",
        "# np.percentile(a, 75) #3rd quantile \n",
        "# max(cnt)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "163"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AnPL7mCUkWb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "6ace476d-dae2-4ef5-888a-2be01572a20e"
      },
      "source": [
        "#0 EMBEDDING LAYERS BY KERAS \n",
        "\n",
        "\n",
        "#check the total words in the train_set \n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "#padded data -- needed when using embedding methods \n",
        "\n",
        "def padd_dataset(X_train, X_val , X_test): \n",
        "\n",
        "\n",
        "  #tokenize data \n",
        "  tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(X_train+X_val) #use the train_dataset for making a dictionary\n",
        "\n",
        "  total_count = len(tokenizer.word_index) \n",
        "  # print(total_count)\n",
        "\n",
        "\n",
        "  #make a vocab_size ::\n",
        "  vocab_size = total_count +1 #for padding 0  : data has vocab_size words \n",
        "\n",
        "  #list of lists of int-encoding\n",
        "  X_train = tokenizer.texts_to_sequences(X_train) #정수 리스트 \n",
        "  X_val = tokenizer.texts_to_sequences(X_val)\n",
        "  X_test = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "  print('tokenizing is finished')\n",
        "\n",
        "  #padd dataset for same length \n",
        "\n",
        "  temp_list = []\n",
        "\n",
        "  total_list = list(X_train) + list(X_val) + list(X_test)\n",
        "  # print(total_list[:10])\n",
        "\n",
        "  cnt= []\n",
        "  for i in range(0, len(total_list)):\n",
        "    cnt.append(len(total_list[i]))\n",
        "\n",
        "  avg_len = sum(cnt) / len(cnt) #평균 : 165.28 \n",
        "  max_len = max(cnt) #가장 긴 문장 (가장 단어가 많은 문장)\n",
        "  #text를 이용하면 8691\n",
        "\n",
        "  # max_len = 200 #길이를 제한한다 \n",
        "    \n",
        "  print('starts to padd the dataset')\n",
        "  #padd the vectors with post padding \n",
        "\n",
        "  X_train = pad_sequences(X_train, maxlen = max_len, padding = 'post')\n",
        "  X_val = pad_sequences(X_val, maxlen = max_len, padding = 'post')\n",
        "  X_test = pad_sequences(X_test, maxlen = max_len, padding = 'post')\n",
        "\n",
        "\n",
        "  return X_train, X_val, X_test,tokenizer,vocab_size,max_len\n",
        "\n",
        "\n",
        "X_train_padd, X_val_padd, X_test_padd, tokenizer, vocab_size, max_len = padd_dataset(X_train, X_val , X_test)\n",
        "#vocab_size: total words in dataset with index starting at 1 \n",
        "#max_len: longest sentence which has max length of number of  words \n",
        "\n",
        "#tokenizer.word_index : 단어에 매칭된 인덱스를 알수있음 \n",
        "\n",
        "\n",
        "vocab_size #총단어수 :  10759\n",
        "max_len #163\n",
        "\n",
        "X_train_padd.shape \n",
        "X_val_padd.shape  \n",
        "\n",
        "X_test_padd.shape #(1158, 8691)\n",
        "\n",
        "\n",
        "X_train_padd #array padded with zeros in back "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tokenizing is finished\n",
            "starts to padd the dataset\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 391,  400,    6, ...,    0,    0,    0],\n",
              "       [5636,   14,  581, ...,    0,    0,    0],\n",
              "       [ 522,  130, 1110, ...,    0,    0,    0],\n",
              "       ...,\n",
              "       [  61, 3946,    0, ...,    0,    0,    0],\n",
              "       [ 301,  187, 2004, ...,    0,    0,    0],\n",
              "       [ 488,  361,  917, ...,    0,    0,    0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVZiIrjsVHde",
        "colab_type": "text"
      },
      "source": [
        "# **(4+) WORD2VEC on dataset, load pretrained word2vec too**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbDAcM6sVGVE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "526ae908-018d-4972-c165-12fc02818408"
      },
      "source": [
        "#1 WORD2VEC  --uses tokenized datasets \n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "#X_train+X_val : list of tokenized word sentences \n",
        "model = Word2Vec(sentences=X_train+X_val, size=max_len, window=5, min_count=10, workers=4, sg=0)  #cbow 이용 \n",
        "#size: vector dimension , (word_num, 8691)  \n",
        "\n",
        "model.wv.vectors.shape \n",
        "#size = 워드 벡터의 특징 값. 즉, 임베딩 된 벡터의 차원 , \n",
        "#window = 컨텍스트 윈도우 크기 ,  -> 앞뒤로 몇개의 단어를 사용할 것인지 \n",
        "#min_count = 단어 최소 빈도 수 제한 (빈도가 적은 단어들은 학습하지 않는다.)\n",
        "#workers = 학습을 위한 프로세스 수,\n",
        "#sg = 0은 CBOW, 1은 Skip-gram.\n",
        "\n",
        "#see the results of word2vec \n",
        "word2vec_matrix = model.wv\n",
        "vocab= word2vec_matrix.vocab.keys() #dictionary \n",
        "\n",
        "#word_vector: this is the vector that is resulted in the word2vec -> use this matrix in modeling \n",
        "model.wv.vectors.shape \n",
        "\n",
        "\n",
        "word2vec_embedding = np.zeros((vocab_size, max_len))\n",
        "\n",
        "for i,word in enumerate(vocab): # 훈련 데이터의 단어 집합에서 단어를 1개씩 꺼내온다.\n",
        "    i= i+1\n",
        "    # print(word,str(i))\n",
        "    # print(word2vec_matrix[word])\n",
        "    word2vec_embedding[i] = word2vec_matrix[word] # 임수 변수의 값을 단어와 맵핑되는 인덱스의 행에 삽입\n",
        "    # print(word2vec_embedding)\n",
        "    \n",
        "word2vec_embedding #my word2vec saved into a array \n",
        "word2vec_embedding.shape #(10759, 163)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10759, 163)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVCqarb8VhRj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "outputId": "b299cd0a-b22d-46bd-cd1e-3b54189c7dbd"
      },
      "source": [
        "\n",
        "#2 PRETRAINED EMBEDDING LAYERS \n",
        "\n",
        "#using embedding pre-trained- match on my dataset \n",
        "\n",
        "#사용법 :  Embedding에 사전 훈련된 embedding_matrix를 입력으로 넣어주고 모델을 학습시킨다\n",
        "#불러온 훈련된 매트릭스의 차원만큼 0으로 채운다. \n",
        "#만약 훈련된 매트릭스가 (100000,300)이면 100000개의 단어가 300차원으로 포현되어있으니, \n",
        "#embedding_matrix = np.zeros((vocab_size, 300)) 나의 단어수,300차원으로 0을 채워준다 \n",
        "\n",
        "import gensim\n",
        "f = gensim.models.Word2Vec.load('ko.bin')\n",
        "\n",
        "\n",
        "f.wv.vectors.shape \n",
        "\n",
        "\n",
        "pretrain = f.wv    \n",
        "\n",
        "#check for my words \n",
        "def get_vector(word):\n",
        "    if word in pretrain:\n",
        "        return pretrain[word]\n",
        "    else:\n",
        "        return None #pretrained matrix 에 없으면 0으로 남는다 \n",
        "\n",
        "\n",
        "#make an embedding matrix to save the words in my data \n",
        "embedding_matrix = np.zeros((vocab_size, 163)) #use all of the vectors \n",
        "\n",
        "for word,i in tokenizer.word_index.items(): # 훈련 데이터의 단어 집합에서 단어와 정수 인덱스를 1개씩 꺼내온다.\n",
        "    temp = get_vector(word) # 단어(key) 해당되는 임베딩 벡터의 값(value)를 임시 변수에 저장\n",
        "    # print(i)\n",
        "    # print(word)\n",
        "    # print(temp)\n",
        "    if temp is not None: # 만약 None이 아니라면 임베딩 벡터의 값을 리턴받은 것이므로\n",
        "        embedding_matrix[i] = temp \n",
        "\n",
        "    # print(embedding_matrix)\n",
        "\n",
        "\n",
        "embedding_matrix.shape #(10759, 200)\n",
        "embedding_matrix # matrix with our words : lots of 0 are inside\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-b25e23b29fdc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m# print(temp)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtemp\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# 만약 None이 아니라면 임베딩 벡터의 값을 리턴받은 것이므로\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0membedding_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m# print(embedding_matrix)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (200) into shape (163)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eqcdc7POVwk5",
        "colab_type": "text"
      },
      "source": [
        "# **(4) Building a Model**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6sHvI-4Vwtd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "from tensorflow.keras.layers import Embedding, Dense, LSTM, Flatten, SimpleRNN\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "#embedding 에서 \n",
        "#1) word2vec을 쓰거나, \n",
        "#2) embedding 을 위해 만든 padd data 를 쓴다\n",
        "#3) pretrained embedded layer을 쓴다 \n",
        "\n",
        "#(1)word2vec\n",
        "\n",
        "# model.add(Embedding(vocab_size, output_dim= 45, weights=[word2vec_embedding], input_length=max_len , trainable=False))  \n",
        "\n",
        "#vocab_size = word2vec_matrix.shape[0]\n",
        "#output_dim : word2vec만들때 설정한 size (100) :word2vec_matrix.shape[1]\n",
        "\n",
        "\n",
        "#(2)embedding layer \n",
        "# model.add(Embedding(int(vocab_size),output_dim= max_len, input_length= int((max_len))))\n",
        "\n",
        "\n",
        "#(3)pretrained embedded layer \n",
        "#trainable;이미 훈련된 임베딩 메트릭스라 훈련안함\n",
        "# model.add(Embedding(vocab_size, output_dim= 200, weights=[embedding_matrix], input_length=max_len, trainable=False)) #output_dim : columm  \n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4) #4번동안 작아지면 멈춤 \n",
        "mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True) "
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1AXOTHjldFz",
        "colab_type": "text"
      },
      "source": [
        "**0.Without Embedding Matrix(using embedding layer in sklearn)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WtU2IyzWp-3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "outputId": "70843400-592f-42f4-96e5-d9ab4001ed93"
      },
      "source": [
        "#1 RNN  \n",
        "\n",
        "\n",
        "def RNN_model(X_train_padd,train_y_onehot,X_val_padd,val_y_onehot):\n",
        "  #model building \n",
        "  model = Sequential()\n",
        "  model.add(Embedding(int(vocab_size),output_dim= max_len, input_length= int((max_len))))\n",
        "  model.add(SimpleRNN(32)) # RNN 셀의 unit= 32\n",
        "  model.add(Dense(10, activation = 'relu'))\n",
        "  model.add(Dense(7, activation='softmax')) #7 categories \n",
        "  model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy']) #categorical_crossentropy : multi class category \n",
        "  model.summary()\n",
        "\n",
        "  return model \n",
        "\n",
        "\n",
        "#fit to train \n",
        "rnn= RNN_model(X_train_padd,train_y_onehot,X_val_padd,val_y_onehot)\n",
        "\n",
        "rnn.fit(X_train_padd, train_y_onehot, epochs=20, batch_size=64,validation_data=(X_val_padd, val_y_onehot), callbacks=[es, mc])\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 163, 163)          1753717   \n",
            "_________________________________________________________________\n",
            "simple_rnn (SimpleRNN)       (None, 32)                6272      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                330       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 7)                 77        \n",
            "=================================================================\n",
            "Total params: 1,760,396\n",
            "Trainable params: 1,760,396\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "130/131 [============================>.] - ETA: 0s - loss: 1.8765 - accuracy: 0.2905WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "131/131 [==============================] - 9s 67ms/step - loss: 1.8765 - accuracy: 0.2905 - val_loss: 1.8742 - val_accuracy: 0.2872\n",
            "Epoch 2/20\n",
            "130/131 [============================>.] - ETA: 0s - loss: 1.8674 - accuracy: 0.2901WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "131/131 [==============================] - 8s 65ms/step - loss: 1.8678 - accuracy: 0.2897 - val_loss: 1.9026 - val_accuracy: 0.2867\n",
            "Epoch 3/20\n",
            "130/131 [============================>.] - ETA: 0s - loss: 1.8590 - accuracy: 0.2919WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "131/131 [==============================] - 9s 65ms/step - loss: 1.8592 - accuracy: 0.2918 - val_loss: 1.9125 - val_accuracy: 0.2872\n",
            "Epoch 4/20\n",
            "130/131 [============================>.] - ETA: 0s - loss: 1.8505 - accuracy: 0.2922WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "131/131 [==============================] - 9s 65ms/step - loss: 1.8506 - accuracy: 0.2918 - val_loss: 1.9344 - val_accuracy: 0.2872\n",
            "Epoch 5/20\n",
            "130/131 [============================>.] - ETA: 0s - loss: 1.8174 - accuracy: 0.2942WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "131/131 [==============================] - 8s 65ms/step - loss: 1.8177 - accuracy: 0.2941 - val_loss: 1.7955 - val_accuracy: 0.2934\n",
            "Epoch 6/20\n",
            "131/131 [==============================] - ETA: 0s - loss: 1.7325 - accuracy: 0.3221WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "131/131 [==============================] - 9s 65ms/step - loss: 1.7325 - accuracy: 0.3221 - val_loss: 1.7740 - val_accuracy: 0.3337\n",
            "Epoch 7/20\n",
            "130/131 [============================>.] - ETA: 0s - loss: 1.6516 - accuracy: 0.3730WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "131/131 [==============================] - 8s 65ms/step - loss: 1.6519 - accuracy: 0.3731 - val_loss: 1.9949 - val_accuracy: 0.2430\n",
            "Epoch 8/20\n",
            "130/131 [============================>.] - ETA: 0s - loss: 1.6124 - accuracy: 0.3874WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "131/131 [==============================] - 9s 65ms/step - loss: 1.6129 - accuracy: 0.3871 - val_loss: 1.8013 - val_accuracy: 0.3322\n",
            "Epoch 9/20\n",
            "130/131 [============================>.] - ETA: 0s - loss: 1.5612 - accuracy: 0.4103WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "131/131 [==============================] - 9s 65ms/step - loss: 1.5614 - accuracy: 0.4102 - val_loss: 1.8831 - val_accuracy: 0.3284\n",
            "Epoch 10/20\n",
            "131/131 [==============================] - ETA: 0s - loss: 1.5427 - accuracy: 0.4212WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "131/131 [==============================] - 9s 66ms/step - loss: 1.5427 - accuracy: 0.4212 - val_loss: 1.7840 - val_accuracy: 0.3591\n",
            "Epoch 00010: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa1e85c5208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaHkz-XYhtE4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 691
        },
        "outputId": "469d6513-8e1d-466f-fcb6-fa18a7718054"
      },
      "source": [
        "\n",
        "#2 LSTM - NOT USING EMBEDDED LAYER \n",
        "\n",
        "\n",
        "#make embedding layer using keras \n",
        "\n",
        "#임베딩 층의 입력으로 사용하기 위해서 입력 시퀀스의 각 단어들은 모두 정수 인코딩이 되어있어야 합니다.\n",
        "#어떤 단어 → 단어에 부여된 고유한 정수값 → 임베딩 층 통과 → 밀집 벡터\n",
        "\n",
        "from tensorflow.keras.layers import Embedding, Dense, LSTM, Flatten\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "\n",
        "\n",
        "def LSTM_model(X_train_padd,train_y_onehot,X_val_padd,val_y_onehot):\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(int(vocab_size),output_dim= max_len, input_length= int((max_len))))\n",
        "  #vocab_size ; +1 because embedding index starts at 1 (not 0) :did it in before cell \n",
        "  #vocab_size= how many letters when using tokenizer \n",
        "  #input_length=max_len : the total vector length (after padding)\n",
        "\n",
        "\n",
        "  model.add(LSTM(128, return_sequences=True ))    \n",
        "  \n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(20, activation= 'relu'))\n",
        "\n",
        "\n",
        "  model.add(Dense(7, activation='softmax')) #7 categories \n",
        "  model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy']) #categorical_crossentropy : multi class category \n",
        "  model.summary()\n",
        "\n",
        "  return model \n",
        "\n",
        "#fit to train \n",
        "\n",
        "lstm =LSTM_model(X_train_padd,train_y_onehot,X_val_padd,val_y_onehot)\n",
        "lstm.fit(X_train_padd, train_y_onehot, epochs=20, batch_size=64,validation_data=(X_val_padd, val_y_onehot), callbacks=[es, mc])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 163, 163)          1753717   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 163, 128)          149504    \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 20864)             0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 20)                417300    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 7)                 147       \n",
            "=================================================================\n",
            "Total params: 2,320,668\n",
            "Trainable params: 2,320,668\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "131/131 [==============================] - ETA: 0s - loss: 1.7181 - accuracy: 0.3609WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "131/131 [==============================] - 59s 454ms/step - loss: 1.7181 - accuracy: 0.3609 - val_loss: 1.5889 - val_accuracy: 0.3917\n",
            "Epoch 2/20\n",
            "131/131 [==============================] - ETA: 0s - loss: 1.1543 - accuracy: 0.6064WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "131/131 [==============================] - 58s 443ms/step - loss: 1.1543 - accuracy: 0.6064 - val_loss: 1.2691 - val_accuracy: 0.5738\n",
            "Epoch 3/20\n",
            "131/131 [==============================] - ETA: 0s - loss: 0.8185 - accuracy: 0.7433WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "131/131 [==============================] - 59s 452ms/step - loss: 0.8185 - accuracy: 0.7433 - val_loss: 1.1920 - val_accuracy: 0.6381\n",
            "Epoch 4/20\n",
            "131/131 [==============================] - ETA: 0s - loss: 0.6270 - accuracy: 0.8100WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "131/131 [==============================] - 59s 447ms/step - loss: 0.6270 - accuracy: 0.8100 - val_loss: 1.2548 - val_accuracy: 0.6309\n",
            "Epoch 5/20\n",
            "131/131 [==============================] - ETA: 0s - loss: 0.5011 - accuracy: 0.8480WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "131/131 [==============================] - 59s 449ms/step - loss: 0.5011 - accuracy: 0.8480 - val_loss: 1.3129 - val_accuracy: 0.6218\n",
            "Epoch 6/20\n",
            "131/131 [==============================] - ETA: 0s - loss: 0.4174 - accuracy: 0.8731WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "131/131 [==============================] - 59s 448ms/step - loss: 0.4174 - accuracy: 0.8731 - val_loss: 1.4571 - val_accuracy: 0.6045\n",
            "Epoch 7/20\n",
            "131/131 [==============================] - ETA: 0s - loss: 0.3452 - accuracy: 0.8969WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "131/131 [==============================] - 58s 445ms/step - loss: 0.3452 - accuracy: 0.8969 - val_loss: 1.5464 - val_accuracy: 0.6170\n",
            "Epoch 00007: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa1e8cd6278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNQUIR-sk9PI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 790
        },
        "outputId": "c7005add-6210-429f-dc86-dcc9bc9e0e97"
      },
      "source": [
        "#3 CNN --without embedding matrix used   \n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Dropout, Conv1D, GlobalMaxPooling1D, Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "\n",
        "def cnn_model(X_train_padd,train_y_onehot,X_val_padd,val_y_onehot):\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(vocab_size, 256)) #embedding dimenstion =256 -> conv1d dimenstion = 256으로 맞춰준다 \n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(Conv1D(256, 3, padding='valid', activation='relu')) #filter_size= 3 \n",
        "  model.add(GlobalMaxPooling1D())\n",
        "  model.add(Dropout(0.5)) \n",
        "  model.add(Flatten()) #flatten을 진행해야, activation 진행가능 (CNN특징) -> (summary확인하기 ) 2차원에서 1차원으로! \n",
        "  model.add(Dense(128, activation='relu')) \n",
        "\n",
        "  model.add(Dense(7, activation='softmax')) #7 categories \n",
        "  model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy']) #categorical_crossentropy : multi class category \n",
        "  model.summary()\n",
        "\n",
        "  return model \n",
        "\n",
        "cnn =cnn_model(X_train_padd,train_y_onehot,X_val_padd,val_y_onehot)\n",
        "cnn.fit(X_train_padd, train_y_onehot, epochs=20, batch_size=64,validation_data=(X_val_padd, val_y_onehot), callbacks=[es, mc])\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, None, 256)         2754304   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, None, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, None, 256)         196864    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 7)                 903       \n",
            "=================================================================\n",
            "Total params: 2,984,967\n",
            "Trainable params: 2,984,967\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "131/131 [==============================] - ETA: 0s - loss: 1.6831 - accuracy: 0.3626WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "131/131 [==============================] - 42s 318ms/step - loss: 1.6831 - accuracy: 0.3626 - val_loss: 1.4722 - val_accuracy: 0.4789\n",
            "Epoch 2/20\n",
            "131/131 [==============================] - ETA: 0s - loss: 1.2347 - accuracy: 0.6010WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "131/131 [==============================] - 42s 318ms/step - loss: 1.2347 - accuracy: 0.6010 - val_loss: 1.1398 - val_accuracy: 0.6376\n",
            "Epoch 3/20\n",
            "131/131 [==============================] - ETA: 0s - loss: 0.9072 - accuracy: 0.7221WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "131/131 [==============================] - 42s 319ms/step - loss: 0.9072 - accuracy: 0.7221 - val_loss: 1.0791 - val_accuracy: 0.6544\n",
            "Epoch 4/20\n",
            "131/131 [==============================] - ETA: 0s - loss: 0.7137 - accuracy: 0.7808WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "131/131 [==============================] - 46s 354ms/step - loss: 0.7137 - accuracy: 0.7808 - val_loss: 1.0882 - val_accuracy: 0.6596\n",
            "Epoch 5/20\n",
            "131/131 [==============================] - ETA: 0s - loss: 0.5701 - accuracy: 0.8294WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "131/131 [==============================] - 42s 320ms/step - loss: 0.5701 - accuracy: 0.8294 - val_loss: 1.1624 - val_accuracy: 0.6596\n",
            "Epoch 6/20\n",
            "131/131 [==============================] - ETA: 0s - loss: 0.4567 - accuracy: 0.8661WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "131/131 [==============================] - 42s 318ms/step - loss: 0.4567 - accuracy: 0.8661 - val_loss: 1.2092 - val_accuracy: 0.6577\n",
            "Epoch 7/20\n",
            "131/131 [==============================] - ETA: 0s - loss: 0.3708 - accuracy: 0.8930WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "131/131 [==============================] - 41s 315ms/step - loss: 0.3708 - accuracy: 0.8930 - val_loss: 1.2783 - val_accuracy: 0.6544\n",
            "Epoch 00007: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa1dea16fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2_ne2-xlo6G",
        "colab_type": "text"
      },
      "source": [
        "**1.Using embedding matrix(pretrained, selftrained)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPVGeTtQiUQ7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658
        },
        "outputId": "832b42cc-d6f0-468b-b4df-89ea58b280d6"
      },
      "source": [
        "\n",
        "#1 LSTM -  USING EMBEDDED LAYER  : word2vec / embedding_matrix\n",
        "\n",
        "def LSTM_model_embedded(X_train_padd,train_y_onehot,X_val_padd,val_y_onehot, matrix): #matrix: word2vec_embedding / embedding_matrix\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Embedding(vocab_size, output_dim=max_len , weights=[matrix], input_length=max_len , trainable=True)) #fine tunning \n",
        "\n",
        "  model.add(LSTM(128, return_sequences=True ))    \n",
        "\n",
        "  model.add(Flatten())\n",
        "\n",
        "  model.add(Dense(7, activation='softmax')) #7 categories \n",
        "  model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy']) #categorical_crossentropy : multi class category \n",
        "  model.summary()\n",
        "\n",
        "  return model \n",
        "\n",
        "\n",
        "\n",
        "#fit to train  -- selftrained\n",
        "lstm_selftrain=LSTM_model_embedded(X_train_padd,train_y_onehot,X_val_padd,val_y_onehot, word2vec_embedding)\n",
        "lstm_selftrain.fit(X_train_padd, train_y_onehot, epochs=20, batch_size=128,validation_data=(X_val_padd, val_y_onehot), callbacks=[es, mc])\n",
        "#increase batchsize since there is no time "
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (None, 163, 163)          1753717   \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 163, 128)          149504    \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 20864)             0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 7)                 146055    \n",
            "=================================================================\n",
            "Total params: 2,049,276\n",
            "Trainable params: 2,049,276\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "66/66 [==============================] - ETA: 0s - loss: 1.7499 - accuracy: 0.3317WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "66/66 [==============================] - 47s 709ms/step - loss: 1.7499 - accuracy: 0.3317 - val_loss: 1.7748 - val_accuracy: 0.2824\n",
            "Epoch 2/20\n",
            "66/66 [==============================] - ETA: 0s - loss: 1.3753 - accuracy: 0.5025WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "66/66 [==============================] - 45s 682ms/step - loss: 1.3753 - accuracy: 0.5025 - val_loss: 1.3592 - val_accuracy: 0.4827\n",
            "Epoch 3/20\n",
            "66/66 [==============================] - ETA: 0s - loss: 1.0599 - accuracy: 0.6475WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "66/66 [==============================] - 45s 681ms/step - loss: 1.0599 - accuracy: 0.6475 - val_loss: 1.2388 - val_accuracy: 0.6012\n",
            "Epoch 4/20\n",
            "66/66 [==============================] - ETA: 0s - loss: 0.8015 - accuracy: 0.7439WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "66/66 [==============================] - 45s 683ms/step - loss: 0.8015 - accuracy: 0.7439 - val_loss: 1.3076 - val_accuracy: 0.6103\n",
            "Epoch 5/20\n",
            "66/66 [==============================] - ETA: 0s - loss: 0.6231 - accuracy: 0.8071WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "66/66 [==============================] - 45s 680ms/step - loss: 0.6231 - accuracy: 0.8071 - val_loss: 1.3577 - val_accuracy: 0.5757\n",
            "Epoch 6/20\n",
            "66/66 [==============================] - ETA: 0s - loss: 0.4934 - accuracy: 0.8478WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "66/66 [==============================] - 47s 717ms/step - loss: 0.4934 - accuracy: 0.8478 - val_loss: 1.3167 - val_accuracy: 0.6194\n",
            "Epoch 7/20\n",
            "66/66 [==============================] - ETA: 0s - loss: 0.3896 - accuracy: 0.8820WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "66/66 [==============================] - 47s 706ms/step - loss: 0.3896 - accuracy: 0.8820 - val_loss: 1.5763 - val_accuracy: 0.5690\n",
            "Epoch 00007: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa1df3f00b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCMq3LLsks6n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658
        },
        "outputId": "2b5e8436-c7c9-4639-8f47-e51a779b8197"
      },
      "source": [
        "#using pretrained word2vec\n",
        "\n",
        "lstm_pretrained=LSTM_model_embedded(X_train_padd,train_y_onehot,X_val_padd,val_y_onehot, embedding_matrix)\n",
        "lstm_pretrained.fit(X_train_padd, train_y_onehot, epochs=10, batch_size=256,validation_data=(X_val_padd, val_y_onehot), callbacks=[es, mc])\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_10 (Embedding)     (None, 163, 163)          1753717   \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 163, 128)          149504    \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 20864)             0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 7)                 146055    \n",
            "=================================================================\n",
            "Total params: 2,049,276\n",
            "Trainable params: 2,049,276\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "33/33 [==============================] - ETA: 0s - loss: 1.7855 - accuracy: 0.3203WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "33/33 [==============================] - 36s 1s/step - loss: 1.7855 - accuracy: 0.3203 - val_loss: 1.5182 - val_accuracy: 0.4132\n",
            "Epoch 2/10\n",
            "33/33 [==============================] - ETA: 0s - loss: 1.2611 - accuracy: 0.5705WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "33/33 [==============================] - 36s 1s/step - loss: 1.2611 - accuracy: 0.5705 - val_loss: 1.1818 - val_accuracy: 0.6016\n",
            "Epoch 3/10\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.8596 - accuracy: 0.7300WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "33/33 [==============================] - 37s 1s/step - loss: 0.8596 - accuracy: 0.7300 - val_loss: 1.1316 - val_accuracy: 0.6472\n",
            "Epoch 4/10\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.5977 - accuracy: 0.8179WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "33/33 [==============================] - 37s 1s/step - loss: 0.5977 - accuracy: 0.8179 - val_loss: 1.2199 - val_accuracy: 0.6261\n",
            "Epoch 5/10\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.4389 - accuracy: 0.8667WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "33/33 [==============================] - 37s 1s/step - loss: 0.4389 - accuracy: 0.8667 - val_loss: 1.2584 - val_accuracy: 0.6419\n",
            "Epoch 6/10\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.3412 - accuracy: 0.8946WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "33/33 [==============================] - 37s 1s/step - loss: 0.3412 - accuracy: 0.8946 - val_loss: 1.3247 - val_accuracy: 0.6323\n",
            "Epoch 7/10\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.2551 - accuracy: 0.9261WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "33/33 [==============================] - 37s 1s/step - loss: 0.2551 - accuracy: 0.9261 - val_loss: 1.4725 - val_accuracy: 0.6189\n",
            "Epoch 00007: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa1dcebc5f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwkLfN_zlRa9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 957
        },
        "outputId": "58377e3b-2244-40db-dd66-3dc57e27e39b"
      },
      "source": [
        "#2 CNN --using embedding matrix \n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Dropout, Conv1D, GlobalMaxPooling1D, Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "\n",
        "def cnn_model(X_train_padd,train_y_onehot,X_val_padd,val_y_onehot, matrix):\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(vocab_size, output_dim=max_len , weights=[matrix], input_length=max_len , trainable=True)) \n",
        "  \n",
        "  #embedding dimenstion, conv1d dimenstion = max_len 으로 맞춰준다 \n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(Conv1D(max_len, 3, padding='valid', activation='relu')) #filter_size= 3 \n",
        "  model.add(GlobalMaxPooling1D())\n",
        "  model.add(Dropout(0.5)) \n",
        "\n",
        "\n",
        "  model.add(Flatten()) #flatten을 진행해야, activation 진행가능 (CNN특징) -> (summary확인하기 ) 2차원에서 1차원으로! \n",
        "  model.add(Dense(32, activation='relu')) \n",
        "\n",
        "  model.add(Dense(7, activation='softmax')) #7 categories \n",
        "  model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy']) #categorical_crossentropy : multi class category \n",
        "  model.summary()\n",
        "\n",
        "  return model \n",
        "\n",
        "cnn_pretrained= cnn_model(X_train_padd,train_y_onehot,X_val_padd,val_y_onehot, embedding_matrix)\n",
        "cnn_pretrained.fit(X_train_padd, train_y_onehot, epochs=10, batch_size=512,validation_data=(X_val_padd, val_y_onehot), callbacks=[es, mc])\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_12 (Embedding)     (None, 163, 163)          1753717   \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 163, 163)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 161, 163)          79870     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_2 (Glob (None, 163)               0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 163)               0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 163)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 32)                5248      \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 7)                 231       \n",
            "=================================================================\n",
            "Total params: 1,839,066\n",
            "Trainable params: 1,839,066\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "17/17 [==============================] - ETA: 0s - loss: 1.9422 - accuracy: 0.2825WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "17/17 [==============================] - 19s 1s/step - loss: 1.9422 - accuracy: 0.2825 - val_loss: 1.9392 - val_accuracy: 0.2872\n",
            "Epoch 2/10\n",
            "17/17 [==============================] - ETA: 0s - loss: 1.9370 - accuracy: 0.2918WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "17/17 [==============================] - 19s 1s/step - loss: 1.9370 - accuracy: 0.2918 - val_loss: 1.9349 - val_accuracy: 0.2872\n",
            "Epoch 3/10\n",
            "17/17 [==============================] - ETA: 0s - loss: 1.9326 - accuracy: 0.2918WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "17/17 [==============================] - 19s 1s/step - loss: 1.9326 - accuracy: 0.2918 - val_loss: 1.9308 - val_accuracy: 0.2872\n",
            "Epoch 4/10\n",
            "17/17 [==============================] - ETA: 0s - loss: 1.9285 - accuracy: 0.2918WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "17/17 [==============================] - 19s 1s/step - loss: 1.9285 - accuracy: 0.2918 - val_loss: 1.9270 - val_accuracy: 0.2872\n",
            "Epoch 5/10\n",
            " 9/17 [==============>...............] - ETA: 8s - loss: 1.9263 - accuracy: 0.2843"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-63a9157bb064>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mcnn_pretrained\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mcnn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_padd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_y_onehot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_val_padd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_y_onehot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mcnn_pretrained\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_padd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y_onehot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val_padd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y_onehot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkbScihym4yw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 792
        },
        "outputId": "6e6359c0-a8e9-43d8-9f76-a6f0aa4366bd"
      },
      "source": [
        "cnn_selftrained= cnn_model(X_train_padd,train_y_onehot,X_val_padd,val_y_onehot, embedding_matrix)\n",
        "cnn_selftrained.fit(X_train_padd, train_y_onehot, epochs=10, batch_size=512,validation_data=(X_val_padd, val_y_onehot), callbacks=[es, mc])\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_13 (Embedding)     (None, 163, 163)          1753717   \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 163, 163)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 161, 163)          79870     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_3 (Glob (None, 163)               0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 163)               0         \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 163)               0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 32)                5248      \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 7)                 231       \n",
            "=================================================================\n",
            "Total params: 1,839,066\n",
            "Trainable params: 1,839,066\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "17/17 [==============================] - ETA: 0s - loss: 1.9422 - accuracy: 0.2815WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "17/17 [==============================] - 21s 1s/step - loss: 1.9422 - accuracy: 0.2815 - val_loss: 1.9392 - val_accuracy: 0.2872\n",
            "Epoch 2/10\n",
            " 1/17 [>.............................] - ETA: 0s - loss: 1.9384 - accuracy: 0.3086"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-a864039d28b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcnn_selftrained\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mcnn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_padd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_y_onehot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_val_padd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_y_onehot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcnn_selftrained\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_padd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y_onehot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val_padd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y_onehot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dasS-fIjht19",
        "colab_type": "text"
      },
      "source": [
        "# **(5) Evaluation of the Model**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uA1CtVYeV-Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def evaluate(X_test_padd,test_y_onehot,model):\n",
        "  predictions = model.predict_classes(X_test_padd, verbose= 1) \n",
        "  test_y_onehot =  np.argmax(test_y_onehot, axis=1).reshape(-1,)\n",
        "  print(f1_score(test_y_onehot, predictions, average= 'macro'))\n",
        "\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmzSqWSanBN-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "470626eb-d8fc-4016-b17f-255473997609"
      },
      "source": [
        "\n",
        "#evaluation of each models \n",
        "\n",
        "\n",
        "\n",
        "#not using embedding matrix\n",
        "\n",
        "print('rnn evaluation')\n",
        "evaluate(X_test_padd,test_y_onehot,rnn)\n",
        "print('lstm evaluation')\n",
        "evaluate(X_test_padd,test_y_onehot,lstm)\n",
        "print('cnn evaluation')\n",
        "evaluate(X_test_padd,test_y_onehot,cnn)\n",
        "\n",
        "\n",
        "\n",
        "#embedding matrix \n",
        "\n",
        "print('selftrained lstm evaluation')\n",
        "evaluate(X_test_padd,test_y_onehot,lstm_selftrained)\n",
        "\n",
        "print('pretrained lstm evaluation')\n",
        "evaluate(X_test_padd,test_y_onehot,lstm_pretrained)\n",
        "\n",
        "print('selftrained cnn evaluation')\n",
        "evaluate(X_test_padd,test_y_onehot,cnn_selftrained)\n",
        "\n",
        "print('pretrained cnn evaluation')\n",
        "evaluate(X_test_padd,test_y_onehot,cnn_pretrained)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rnn evaluation\n",
            "WARNING:tensorflow:From <ipython-input-32-45587f19f1d7>:4: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "37/37 [==============================] - 0s 11ms/step\n",
            "0.26263148074811893\n",
            "lstm evaluation\n",
            "37/37 [==============================] - 2s 54ms/step\n",
            "0.6412934515346876\n",
            "cnn evaluation\n",
            "37/37 [==============================] - 1s 36ms/step\n",
            "0.6918010990022113\n",
            "selftrained lstm evaluation\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-94757f32a05f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'selftrained lstm evaluation'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_padd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_y_onehot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlstm_selftrained\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pretrained lstm evaluation'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'lstm_selftrained' is not defined"
          ]
        }
      ]
    }
  ]
}